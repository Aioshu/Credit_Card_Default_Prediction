{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest- Default_Card_Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# MOdel library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>defaulted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
       "1   2     120000    2          2         2   26     -1      2      0      0   \n",
       "2   3      90000    2          2         2   34      0      0      0      0   \n",
       "3   4      50000    2          2         1   37      0      0      0      0   \n",
       "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "     ...      BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0    ...              0          0          0         0       689         0   \n",
       "1    ...           3272       3455       3261         0      1000      1000   \n",
       "2    ...          14331      14948      15549      1518      1500      1000   \n",
       "3    ...          28314      28959      29547      2000      2019      1200   \n",
       "4    ...          20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  defaulted  \n",
       "0         0         0         0          1  \n",
       "1      1000         0      2000          1  \n",
       "2      1000      1000      5000          0  \n",
       "3      1100      1069      1000          0  \n",
       "4      9000       689       679          0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the cvs\n",
    "data=pd.read_csv(\"credit-card-default.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0',\n",
       "       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
       "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
       "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
       "       'defaulted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 30000\n",
      "columns: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"rows:\",data.shape[0])\n",
    "print(\"columns:\",data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 25 columns):\n",
      "ID           30000 non-null int64\n",
      "LIMIT_BAL    30000 non-null int64\n",
      "SEX          30000 non-null int64\n",
      "EDUCATION    30000 non-null int64\n",
      "MARRIAGE     30000 non-null int64\n",
      "AGE          30000 non-null int64\n",
      "PAY_0        30000 non-null int64\n",
      "PAY_2        30000 non-null int64\n",
      "PAY_3        30000 non-null int64\n",
      "PAY_4        30000 non-null int64\n",
      "PAY_5        30000 non-null int64\n",
      "PAY_6        30000 non-null int64\n",
      "BILL_AMT1    30000 non-null int64\n",
      "BILL_AMT2    30000 non-null int64\n",
      "BILL_AMT3    30000 non-null int64\n",
      "BILL_AMT4    30000 non-null int64\n",
      "BILL_AMT5    30000 non-null int64\n",
      "BILL_AMT6    30000 non-null int64\n",
      "PAY_AMT1     30000 non-null int64\n",
      "PAY_AMT2     30000 non-null int64\n",
      "PAY_AMT3     30000 non-null int64\n",
      "PAY_AMT4     30000 non-null int64\n",
      "PAY_AMT5     30000 non-null int64\n",
      "PAY_AMT6     30000 non-null int64\n",
      "defaulted    30000 non-null int64\n",
      "dtypes: int64(25)\n",
      "memory usage: 5.7 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>defaulted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>30000.00000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15000.500000</td>\n",
       "      <td>167484.322667</td>\n",
       "      <td>1.603733</td>\n",
       "      <td>1.853133</td>\n",
       "      <td>1.551867</td>\n",
       "      <td>35.485500</td>\n",
       "      <td>-0.016700</td>\n",
       "      <td>-0.133767</td>\n",
       "      <td>-0.166200</td>\n",
       "      <td>-0.220667</td>\n",
       "      <td>...</td>\n",
       "      <td>43262.948967</td>\n",
       "      <td>40311.400967</td>\n",
       "      <td>38871.760400</td>\n",
       "      <td>5663.580500</td>\n",
       "      <td>5.921163e+03</td>\n",
       "      <td>5225.68150</td>\n",
       "      <td>4826.076867</td>\n",
       "      <td>4799.387633</td>\n",
       "      <td>5215.502567</td>\n",
       "      <td>0.221200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8660.398374</td>\n",
       "      <td>129747.661567</td>\n",
       "      <td>0.489129</td>\n",
       "      <td>0.790349</td>\n",
       "      <td>0.521970</td>\n",
       "      <td>9.217904</td>\n",
       "      <td>1.123802</td>\n",
       "      <td>1.197186</td>\n",
       "      <td>1.196868</td>\n",
       "      <td>1.169139</td>\n",
       "      <td>...</td>\n",
       "      <td>64332.856134</td>\n",
       "      <td>60797.155770</td>\n",
       "      <td>59554.107537</td>\n",
       "      <td>16563.280354</td>\n",
       "      <td>2.304087e+04</td>\n",
       "      <td>17606.96147</td>\n",
       "      <td>15666.159744</td>\n",
       "      <td>15278.305679</td>\n",
       "      <td>17777.465775</td>\n",
       "      <td>0.415062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-170000.000000</td>\n",
       "      <td>-81334.000000</td>\n",
       "      <td>-339603.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7500.750000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2326.750000</td>\n",
       "      <td>1763.000000</td>\n",
       "      <td>1256.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>8.330000e+02</td>\n",
       "      <td>390.00000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>252.500000</td>\n",
       "      <td>117.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15000.500000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19052.000000</td>\n",
       "      <td>18104.500000</td>\n",
       "      <td>17071.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>1800.00000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22500.250000</td>\n",
       "      <td>240000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54506.000000</td>\n",
       "      <td>50190.500000</td>\n",
       "      <td>49198.250000</td>\n",
       "      <td>5006.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4505.00000</td>\n",
       "      <td>4013.250000</td>\n",
       "      <td>4031.500000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>891586.000000</td>\n",
       "      <td>927171.000000</td>\n",
       "      <td>961664.000000</td>\n",
       "      <td>873552.000000</td>\n",
       "      <td>1.684259e+06</td>\n",
       "      <td>896040.00000</td>\n",
       "      <td>621000.000000</td>\n",
       "      <td>426529.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID       LIMIT_BAL           SEX     EDUCATION      MARRIAGE  \\\n",
       "count  30000.000000    30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean   15000.500000   167484.322667      1.603733      1.853133      1.551867   \n",
       "std     8660.398374   129747.661567      0.489129      0.790349      0.521970   \n",
       "min        1.000000    10000.000000      1.000000      0.000000      0.000000   \n",
       "25%     7500.750000    50000.000000      1.000000      1.000000      1.000000   \n",
       "50%    15000.500000   140000.000000      2.000000      2.000000      2.000000   \n",
       "75%    22500.250000   240000.000000      2.000000      2.000000      2.000000   \n",
       "max    30000.000000  1000000.000000      2.000000      6.000000      3.000000   \n",
       "\n",
       "                AGE         PAY_0         PAY_2         PAY_3         PAY_4  \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean      35.485500     -0.016700     -0.133767     -0.166200     -0.220667   \n",
       "std        9.217904      1.123802      1.197186      1.196868      1.169139   \n",
       "min       21.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n",
       "25%       28.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "50%       34.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       41.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       79.000000      8.000000      8.000000      8.000000      8.000000   \n",
       "\n",
       "           ...           BILL_AMT4      BILL_AMT5      BILL_AMT6  \\\n",
       "count      ...        30000.000000   30000.000000   30000.000000   \n",
       "mean       ...        43262.948967   40311.400967   38871.760400   \n",
       "std        ...        64332.856134   60797.155770   59554.107537   \n",
       "min        ...      -170000.000000  -81334.000000 -339603.000000   \n",
       "25%        ...         2326.750000    1763.000000    1256.000000   \n",
       "50%        ...        19052.000000   18104.500000   17071.000000   \n",
       "75%        ...        54506.000000   50190.500000   49198.250000   \n",
       "max        ...       891586.000000  927171.000000  961664.000000   \n",
       "\n",
       "            PAY_AMT1      PAY_AMT2      PAY_AMT3       PAY_AMT4  \\\n",
       "count   30000.000000  3.000000e+04   30000.00000   30000.000000   \n",
       "mean     5663.580500  5.921163e+03    5225.68150    4826.076867   \n",
       "std     16563.280354  2.304087e+04   17606.96147   15666.159744   \n",
       "min         0.000000  0.000000e+00       0.00000       0.000000   \n",
       "25%      1000.000000  8.330000e+02     390.00000     296.000000   \n",
       "50%      2100.000000  2.009000e+03    1800.00000    1500.000000   \n",
       "75%      5006.000000  5.000000e+03    4505.00000    4013.250000   \n",
       "max    873552.000000  1.684259e+06  896040.00000  621000.000000   \n",
       "\n",
       "            PAY_AMT5       PAY_AMT6     defaulted  \n",
       "count   30000.000000   30000.000000  30000.000000  \n",
       "mean     4799.387633    5215.502567      0.221200  \n",
       "std     15278.305679   17777.465775      0.415062  \n",
       "min         0.000000       0.000000      0.000000  \n",
       "25%       252.500000     117.750000      0.000000  \n",
       "50%      1500.000000    1500.000000      0.000000  \n",
       "75%      4031.500000    4000.000000      0.000000  \n",
       "max    426529.000000  528666.000000      1.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "LIMIT_BAL    0\n",
       "SEX          0\n",
       "EDUCATION    0\n",
       "MARRIAGE     0\n",
       "AGE          0\n",
       "PAY_0        0\n",
       "PAY_2        0\n",
       "PAY_3        0\n",
       "PAY_4        0\n",
       "PAY_5        0\n",
       "PAY_6        0\n",
       "BILL_AMT1    0\n",
       "BILL_AMT2    0\n",
       "BILL_AMT3    0\n",
       "BILL_AMT4    0\n",
       "BILL_AMT5    0\n",
       "BILL_AMT6    0\n",
       "PAY_AMT1     0\n",
       "PAY_AMT2     0\n",
       "PAY_AMT3     0\n",
       "PAY_AMT4     0\n",
       "PAY_AMT5     0\n",
       "PAY_AMT6     0\n",
       "defaulted    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we did not find any missing value so we can proceed and build model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting features variable to X\n",
    "X=data.drop(\"defaulted\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting response variable to y\n",
    "y=data.defaulted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Default hyperparameters to fit a random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Running the randomforest with defaiult parameter\n",
    "rfc=RandomForestClassifier()\n",
    "\n",
    "# fit the model\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions=rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.95      0.88      6982\n",
      "          1       0.63      0.32      0.43      2018\n",
      "\n",
      "avg / total       0.78      0.81      0.78      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8058888888888889\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\",accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion_matrix:\n",
      "[[6606  376]\n",
      " [1371  647]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion_matrix:\")\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to improve model mopdel preformance. now do the hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters to  tune Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomForestClassifier in module sklearn.ensemble.forest:\n",
      "\n",
      "class RandomForestClassifier(ForestClassifier)\n",
      " |  A random forest classifier.\n",
      " |  \n",
      " |  A random forest is a meta estimator that fits a number of decision tree\n",
      " |  classifiers on various sub-samples of the dataset and use averaging to\n",
      " |  improve the predictive accuracy and control over-fitting.\n",
      " |  The sub-sample size is always the same as the original\n",
      " |  input sample size but the samples are drawn with replacement if\n",
      " |  `bootstrap=True` (default).\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <forest>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : integer, optional (default=10)\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |  criterion : string, optional (default=\"gini\")\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      " |      Note: this parameter is tree-specific.\n",
      " |  \n",
      " |  max_features : int, float, string or None, optional (default=\"auto\")\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a percentage and\n",
      " |        `int(max_features * n_features)` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)` (same as \"auto\").\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_depth : integer or None, optional (default=None)\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int, float, optional (default=2)\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a percentage and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for percentages.\n",
      " |  \n",
      " |  min_samples_leaf : int, float, optional (default=1)\n",
      " |      The minimum number of samples required to be at a leaf node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a percentage and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for percentages.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, optional (default=0.)\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_leaf_nodes : int or None, optional (default=None)\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_split : float,\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``min_impurity_split`` has been deprecated in favor of\n",
      " |         ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.\n",
      " |         Use ``min_impurity_decrease`` instead.\n",
      " |  \n",
      " |  min_impurity_decrease : float, optional (default=0.)\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  bootstrap : boolean, optional (default=True)\n",
      " |      Whether bootstrap samples are used when building trees.\n",
      " |  \n",
      " |  oob_score : bool (default=False)\n",
      " |      Whether to use out-of-bag samples to estimate\n",
      " |      the generalization accuracy.\n",
      " |  \n",
      " |  n_jobs : integer, optional (default=1)\n",
      " |      The number of jobs to run in parallel for both `fit` and `predict`.\n",
      " |      If -1, then the number of jobs is set to the number of cores.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  verbose : int, optional (default=0)\n",
      " |      Controls the verbosity of the tree building process.\n",
      " |  \n",
      " |  warm_start : bool, optional (default=False)\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest.\n",
      " |  \n",
      " |  class_weight : dict, list of dicts, \"balanced\",\n",
      " |      \"balanced_subsample\" or None, optional (default=None)\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one. For\n",
      " |      multi-output problems, a list of dicts can be provided in the same\n",
      " |      order as the columns of y.\n",
      " |  \n",
      " |      Note that for multioutput (including multilabel) weights should be\n",
      " |      defined for each class of every column in its own dict. For example,\n",
      " |      for four-class multilabel classification weights should be\n",
      " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |      The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
      " |      weights are computed based on the bootstrap sample for every tree\n",
      " |      grown.\n",
      " |  \n",
      " |      For multi-output, the weights of each column of y will be multiplied.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  estimators_ : list of DecisionTreeClassifier\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  classes_ : array of shape = [n_classes] or a list of such arrays\n",
      " |      The classes labels (single output problem), or a list of arrays of\n",
      " |      class labels (multi-output problem).\n",
      " |  \n",
      " |  n_classes_ : int or list\n",
      " |      The number of classes (single output problem), or a list containing the\n",
      " |      number of classes for each output (multi-output problem).\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  feature_importances_ : array of shape = [n_features]\n",
      " |      The feature importances (the higher, the more important the feature).\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |  \n",
      " |  oob_decision_function_ : array of shape = [n_samples, n_classes]\n",
      " |      Decision function computed with out-of-bag estimate on the training\n",
      " |      set. If n_estimators is small it might be possible that a data point\n",
      " |      was never left out during the bootstrap. In this case,\n",
      " |      `oob_decision_function_` might contain NaN.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import RandomForestClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>>\n",
      " |  >>> X, y = make_classification(n_samples=1000, n_features=4,\n",
      " |  ...                            n_informative=2, n_redundant=0,\n",
      " |  ...                            random_state=0, shuffle=False)\n",
      " |  >>> clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
      " |  >>> clf.fit(X, y)\n",
      " |  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      " |              max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      " |              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      " |              min_samples_leaf=1, min_samples_split=2,\n",
      " |              min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      " |              oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      " |  >>> print(clf.feature_importances_)\n",
      " |  [ 0.17287856  0.80608704  0.01884792  0.00218648]\n",
      " |  >>> print(clf.predict([[0, 0, 0, 0]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data,\n",
      " |  ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      " |  of the criterion is identical for several splits enumerated during the\n",
      " |  search of the best split. To obtain a deterministic behaviour during\n",
      " |  fitting, ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  DecisionTreeClassifier, ExtraTreesClassifier\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomForestClassifier\n",
      " |      ForestClassifier\n",
      " |      abc.NewBase\n",
      " |      BaseForest\n",
      " |      abc.NewBase\n",
      " |      sklearn.ensemble.base.BaseEnsemble\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False, class_weight=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestClassifier:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class for X.\n",
      " |      \n",
      " |      The predicted class of an input sample is a vote by the trees in\n",
      " |      the forest, weighted by their probability estimates. That is,\n",
      " |      the predicted class is the one with highest mean probability\n",
      " |      estimate across the trees.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array of shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      The predicted class log-probabilities of an input sample is computed as\n",
      " |      the log of the mean predicted class probabilities of the trees in the\n",
      " |      forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      The predicted class probabilities of an input sample are computed as\n",
      " |      the mean predicted class probabilities of the trees in the forest. The\n",
      " |      class probability of a single tree is the fraction of samples of the same\n",
      " |      class in a leaf.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape = [n_samples, n_estimators]\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  decision_path(self, X)\n",
      " |      Return the decision path in the forest\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse csr array, shape = [n_samples, n_nodes]\n",
      " |          Return a node indicator matrix where non zero elements\n",
      " |          indicates that the samples goes through the nodes.\n",
      " |      \n",
      " |      n_nodes_ptr : array of size (n_estimators + 1, )\n",
      " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
      " |          gives the indicator value for the i-th estimator.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The training input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples] or None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Return the feature importances (the higher, the more important the\n",
      " |         feature).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array, shape = [n_features]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble.base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Returns the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Returns iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to understand about the parameters of RandomForestClassifier \n",
    "help(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning_max_depth "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the optimal value of ```Max_depth``` and how value of max_depth impacts the overall accuracy of ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': range(2, 20, 5)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='accuracy',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV to find optimal n_estimators\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# specify the no. of folds for kfold cv\n",
    "n_folds=5\n",
    "\n",
    "# Parameters\n",
    "parameter={\"max_depth\":range(2,20,5)}\n",
    "\n",
    "# Instialise the model\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "\n",
    "# fit tree with training data\n",
    "rf=GridSearchCV(estimator=rf,param_grid=parameter,cv=n_folds,scoring=\"accuracy\")\n",
    "\n",
    "rf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.198162</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>0.807903</td>\n",
       "      <td>0.816234</td>\n",
       "      <td>0.796905</td>\n",
       "      <td>0.802096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805095</td>\n",
       "      <td>0.006568</td>\n",
       "      <td>4</td>\n",
       "      <td>0.809810</td>\n",
       "      <td>0.817965</td>\n",
       "      <td>0.798571</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>0.803464</td>\n",
       "      <td>0.806322</td>\n",
       "      <td>0.006877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.478967</td>\n",
       "      <td>0.032592</td>\n",
       "      <td>0.011067</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>0.820281</td>\n",
       "      <td>0.818377</td>\n",
       "      <td>0.819524</td>\n",
       "      <td>0.822815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819619</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.830823</td>\n",
       "      <td>0.835407</td>\n",
       "      <td>0.834048</td>\n",
       "      <td>0.833522</td>\n",
       "      <td>0.834057</td>\n",
       "      <td>0.833571</td>\n",
       "      <td>0.001509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.767876</td>\n",
       "      <td>0.060248</td>\n",
       "      <td>0.018019</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 12}</td>\n",
       "      <td>0.821233</td>\n",
       "      <td>0.812902</td>\n",
       "      <td>0.815476</td>\n",
       "      <td>0.811622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814714</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>2</td>\n",
       "      <td>0.882374</td>\n",
       "      <td>0.878921</td>\n",
       "      <td>0.878929</td>\n",
       "      <td>0.880602</td>\n",
       "      <td>0.878400</td>\n",
       "      <td>0.879845</td>\n",
       "      <td>0.001466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.924814</td>\n",
       "      <td>0.042440</td>\n",
       "      <td>0.019117</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_depth': 17}</td>\n",
       "      <td>0.809093</td>\n",
       "      <td>0.812426</td>\n",
       "      <td>0.809286</td>\n",
       "      <td>0.812813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810714</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>3</td>\n",
       "      <td>0.924996</td>\n",
       "      <td>0.922019</td>\n",
       "      <td>0.925476</td>\n",
       "      <td>0.927921</td>\n",
       "      <td>0.923219</td>\n",
       "      <td>0.924726</td>\n",
       "      <td>0.002022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.198162      0.006937         0.007833        0.001597   \n",
       "1       0.478967      0.032592         0.011067        0.002092   \n",
       "2       0.767876      0.060248         0.018019        0.004571   \n",
       "3       0.924814      0.042440         0.019117        0.001901   \n",
       "\n",
       "  param_max_depth             params  split0_test_score  split1_test_score  \\\n",
       "0               2   {'max_depth': 2}           0.807903           0.816234   \n",
       "1               7   {'max_depth': 7}           0.820281           0.818377   \n",
       "2              12  {'max_depth': 12}           0.821233           0.812902   \n",
       "3              17  {'max_depth': 17}           0.809093           0.812426   \n",
       "\n",
       "   split2_test_score  split3_test_score       ...         mean_test_score  \\\n",
       "0           0.796905           0.802096       ...                0.805095   \n",
       "1           0.819524           0.822815       ...                0.819619   \n",
       "2           0.815476           0.811622       ...                0.814714   \n",
       "3           0.809286           0.812813       ...                0.810714   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.006568                4            0.809810            0.817965   \n",
       "1        0.001926                1            0.830823            0.835407   \n",
       "2        0.003510                2            0.882374            0.878921   \n",
       "3        0.001586                3            0.924996            0.922019   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.798571            0.801798            0.803464   \n",
       "1            0.834048            0.833522            0.834057   \n",
       "2            0.878929            0.880602            0.878400   \n",
       "3            0.925476            0.927921            0.923219   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.806322         0.006877  \n",
       "1          0.833571         0.001509  \n",
       "2          0.879845         0.001466  \n",
       "3          0.924726         0.002022  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores of GridSearchCV\n",
    "cv_results=rf.cv_results_\n",
    "cv_results=pd.DataFrame(cv_results)\n",
    "\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(cv_results.param_max_depth,cv_results.mean_train_score,label=\"Training Acccuracy\")\n",
    "plt.plot(cv_results.param_max_depth,cv_results.mean_test_score,label=\"Testing Accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After max_depth of 7 the model starting overfitting.so we will stop it growing after 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning n_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the optimal values for n_estimators and impact the overall accuarcies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': range(100, 1500, 400)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Kfolds\n",
    "n_folds=5\n",
    "\n",
    "# Parameters\n",
    "parameters={\"n_estimators\":range(100,1500,400)}\n",
    "\n",
    "# instantiate the model(with max_depth)\n",
    "rf=RandomForestClassifier(max_depth=4)\n",
    "\n",
    "# fit the tree\n",
    "rf=GridSearchCV(estimator=rf,param_grid=parameters,cv=n_folds,scoring=\"accuracy\")\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.901848</td>\n",
       "      <td>0.023787</td>\n",
       "      <td>0.069804</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>100</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "      <td>0.809807</td>\n",
       "      <td>0.814330</td>\n",
       "      <td>0.814524</td>\n",
       "      <td>0.814956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813238</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>1</td>\n",
       "      <td>0.815227</td>\n",
       "      <td>0.815465</td>\n",
       "      <td>0.814881</td>\n",
       "      <td>0.813225</td>\n",
       "      <td>0.812809</td>\n",
       "      <td>0.814321</td>\n",
       "      <td>0.001089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.901691</td>\n",
       "      <td>0.478765</td>\n",
       "      <td>0.356468</td>\n",
       "      <td>0.027668</td>\n",
       "      <td>500</td>\n",
       "      <td>{'n_estimators': 500}</td>\n",
       "      <td>0.807665</td>\n",
       "      <td>0.814568</td>\n",
       "      <td>0.811429</td>\n",
       "      <td>0.813527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811857</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>4</td>\n",
       "      <td>0.813322</td>\n",
       "      <td>0.814810</td>\n",
       "      <td>0.813452</td>\n",
       "      <td>0.811559</td>\n",
       "      <td>0.813225</td>\n",
       "      <td>0.813274</td>\n",
       "      <td>0.001033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.684366</td>\n",
       "      <td>1.386421</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>0.061926</td>\n",
       "      <td>900</td>\n",
       "      <td>{'n_estimators': 900}</td>\n",
       "      <td>0.808141</td>\n",
       "      <td>0.814330</td>\n",
       "      <td>0.811429</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811952</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>2</td>\n",
       "      <td>0.813501</td>\n",
       "      <td>0.814156</td>\n",
       "      <td>0.813214</td>\n",
       "      <td>0.811975</td>\n",
       "      <td>0.813761</td>\n",
       "      <td>0.813321</td>\n",
       "      <td>0.000741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.164701</td>\n",
       "      <td>0.111160</td>\n",
       "      <td>0.882153</td>\n",
       "      <td>0.014557</td>\n",
       "      <td>1300</td>\n",
       "      <td>{'n_estimators': 1300}</td>\n",
       "      <td>0.808141</td>\n",
       "      <td>0.813616</td>\n",
       "      <td>0.811667</td>\n",
       "      <td>0.814003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811905</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>3</td>\n",
       "      <td>0.813382</td>\n",
       "      <td>0.813917</td>\n",
       "      <td>0.813214</td>\n",
       "      <td>0.811499</td>\n",
       "      <td>0.813404</td>\n",
       "      <td>0.813083</td>\n",
       "      <td>0.000826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       2.901848      0.023787         0.069804        0.000649   \n",
       "1      14.901691      0.478765         0.356468        0.027668   \n",
       "2      27.684366      1.386421         0.644779        0.061926   \n",
       "3      37.164701      0.111160         0.882153        0.014557   \n",
       "\n",
       "  param_n_estimators                  params  split0_test_score  \\\n",
       "0                100   {'n_estimators': 100}           0.809807   \n",
       "1                500   {'n_estimators': 500}           0.807665   \n",
       "2                900   {'n_estimators': 900}           0.808141   \n",
       "3               1300  {'n_estimators': 1300}           0.808141   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0           0.814330           0.814524           0.814956       ...          \n",
       "1           0.814568           0.811429           0.813527       ...          \n",
       "2           0.814330           0.811429           0.813765       ...          \n",
       "3           0.813616           0.811667           0.814003       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.813238        0.001898                1            0.815227   \n",
       "1         0.811857        0.002365                4            0.813322   \n",
       "2         0.811952        0.002180                2            0.813501   \n",
       "3         0.811905        0.002078                3            0.813382   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.815465            0.814881            0.813225   \n",
       "1            0.814810            0.813452            0.811559   \n",
       "2            0.814156            0.813214            0.811975   \n",
       "3            0.813917            0.813214            0.811499   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.812809          0.814321         0.001089  \n",
       "1            0.813225          0.813274         0.001033  \n",
       "2            0.813761          0.813321         0.000741  \n",
       "3            0.813404          0.813083         0.000826  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score of RandomForestClassifier\n",
    "cv_results=rf.cv_results_\n",
    "cv_results=pd.DataFrame(cv_results)\n",
    "\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(cv_results.param_n_estimators,cv_results.mean_train_score,label=\"Train Accuracy\")\n",
    "plt.plot(cv_results.param_n_estimators,cv_results.mean_test_score,label=\"Test Accuracy\")\n",
    "plt.xlabel(\"n_estimator\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning max_features\n",
    "\n",
    "Let's see how the model performance varies with ```max_features```, which is the maximum number of features considered for splitting at a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_features': [4, 8, 14, 18, 20, 24]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "kfold=5\n",
    "\n",
    "parameters={\"max_features\":[4,8,14,18,20,24]}\n",
    "\n",
    "rf=RandomForestClassifier(max_depth=4)\n",
    "\n",
    "rf=GridSearchCV(estimator=rf,param_grid=parameters,cv=kfold,scoring=\"accuracy\")\n",
    "\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.310508</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.012089</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_features': 4}</td>\n",
       "      <td>0.808379</td>\n",
       "      <td>0.812188</td>\n",
       "      <td>0.810952</td>\n",
       "      <td>0.808050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810238</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>6</td>\n",
       "      <td>0.813203</td>\n",
       "      <td>0.815465</td>\n",
       "      <td>0.817738</td>\n",
       "      <td>0.807452</td>\n",
       "      <td>0.813821</td>\n",
       "      <td>0.813536</td>\n",
       "      <td>0.003423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.514985</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_features': 8}</td>\n",
       "      <td>0.815520</td>\n",
       "      <td>0.821471</td>\n",
       "      <td>0.818810</td>\n",
       "      <td>0.819719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818619</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>5</td>\n",
       "      <td>0.819513</td>\n",
       "      <td>0.823620</td>\n",
       "      <td>0.823274</td>\n",
       "      <td>0.818701</td>\n",
       "      <td>0.824475</td>\n",
       "      <td>0.821917</td>\n",
       "      <td>0.002341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.819908</td>\n",
       "      <td>0.015847</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>14</td>\n",
       "      <td>{'max_features': 14}</td>\n",
       "      <td>0.822185</td>\n",
       "      <td>0.821471</td>\n",
       "      <td>0.818333</td>\n",
       "      <td>0.824244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820857</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>4</td>\n",
       "      <td>0.824037</td>\n",
       "      <td>0.824871</td>\n",
       "      <td>0.823214</td>\n",
       "      <td>0.823582</td>\n",
       "      <td>0.825427</td>\n",
       "      <td>0.824226</td>\n",
       "      <td>0.000816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.019949</td>\n",
       "      <td>0.014001</td>\n",
       "      <td>0.008901</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>18</td>\n",
       "      <td>{'max_features': 18}</td>\n",
       "      <td>0.823137</td>\n",
       "      <td>0.820995</td>\n",
       "      <td>0.818095</td>\n",
       "      <td>0.825196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821238</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>2</td>\n",
       "      <td>0.824513</td>\n",
       "      <td>0.824156</td>\n",
       "      <td>0.824464</td>\n",
       "      <td>0.823641</td>\n",
       "      <td>0.826260</td>\n",
       "      <td>0.824607</td>\n",
       "      <td>0.000883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.128988</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>0.008881</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_features': 20}</td>\n",
       "      <td>0.820757</td>\n",
       "      <td>0.820519</td>\n",
       "      <td>0.819762</td>\n",
       "      <td>0.827816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821857</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>1</td>\n",
       "      <td>0.824930</td>\n",
       "      <td>0.824871</td>\n",
       "      <td>0.825179</td>\n",
       "      <td>0.824296</td>\n",
       "      <td>0.825844</td>\n",
       "      <td>0.825024</td>\n",
       "      <td>0.000502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.310508      0.008832         0.012089        0.004282   \n",
       "1       0.514985      0.003360         0.009912        0.000233   \n",
       "2       0.819908      0.015847         0.007853        0.002341   \n",
       "3       1.019949      0.014001         0.008901        0.001953   \n",
       "4       1.128988      0.006479         0.008881        0.001945   \n",
       "\n",
       "  param_max_features                params  split0_test_score  \\\n",
       "0                  4   {'max_features': 4}           0.808379   \n",
       "1                  8   {'max_features': 8}           0.815520   \n",
       "2                 14  {'max_features': 14}           0.822185   \n",
       "3                 18  {'max_features': 18}           0.823137   \n",
       "4                 20  {'max_features': 20}           0.820757   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0           0.812188           0.810952           0.808050       ...          \n",
       "1           0.821471           0.818810           0.819719       ...          \n",
       "2           0.821471           0.818333           0.824244       ...          \n",
       "3           0.820995           0.818095           0.825196       ...          \n",
       "4           0.820519           0.819762           0.827816       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.810238        0.001701                6            0.813203   \n",
       "1         0.818619        0.002004                5            0.819513   \n",
       "2         0.820857        0.002360                4            0.824037   \n",
       "3         0.821238        0.002658                2            0.824513   \n",
       "4         0.821857        0.002997                1            0.824930   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.815465            0.817738            0.807452   \n",
       "1            0.823620            0.823274            0.818701   \n",
       "2            0.824871            0.823214            0.823582   \n",
       "3            0.824156            0.824464            0.823641   \n",
       "4            0.824871            0.825179            0.824296   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.813821          0.813536         0.003423  \n",
       "1            0.824475          0.821917         0.002341  \n",
       "2            0.825427          0.824226         0.000816  \n",
       "3            0.826260          0.824607         0.000883  \n",
       "4            0.825844          0.825024         0.000502  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results=rf.cv_results_\n",
    "cv_results=pd.DataFrame(cv_results)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(cv_results.param_max_features,cv_results.mean_train_score,label=\"Train Accuracy\")\n",
    "plt.plot(cv_results.param_max_features,cv_results.mean_test_score,label=\"Test Accuracy\")\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, the training and test scores *both* seem to increase as we increase max_features, and the model doesn't seem to overfit more with increasing max_features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning min_samples_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter **min_samples_leaf** is the minimum number of samples required to be at a leaf node:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_leaf': range(100, 400, 50)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_leaf': range(100, 400, 50)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.600036</td>\n",
       "      <td>0.045294</td>\n",
       "      <td>0.015707</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_leaf': 100}</td>\n",
       "      <td>0.811950</td>\n",
       "      <td>0.819805</td>\n",
       "      <td>0.811905</td>\n",
       "      <td>0.815909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815143</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>2</td>\n",
       "      <td>0.819454</td>\n",
       "      <td>0.822847</td>\n",
       "      <td>0.815179</td>\n",
       "      <td>0.820130</td>\n",
       "      <td>0.822272</td>\n",
       "      <td>0.819976</td>\n",
       "      <td>0.002714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.513414</td>\n",
       "      <td>0.026510</td>\n",
       "      <td>0.012501</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>150</td>\n",
       "      <td>{'min_samples_leaf': 150}</td>\n",
       "      <td>0.819091</td>\n",
       "      <td>0.818615</td>\n",
       "      <td>0.808571</td>\n",
       "      <td>0.822339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816381</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>1</td>\n",
       "      <td>0.819454</td>\n",
       "      <td>0.818858</td>\n",
       "      <td>0.811548</td>\n",
       "      <td>0.816380</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.816322</td>\n",
       "      <td>0.002827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.474990</td>\n",
       "      <td>0.030583</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>200</td>\n",
       "      <td>{'min_samples_leaf': 200}</td>\n",
       "      <td>0.806713</td>\n",
       "      <td>0.806237</td>\n",
       "      <td>0.810238</td>\n",
       "      <td>0.815432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810810</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>4</td>\n",
       "      <td>0.807786</td>\n",
       "      <td>0.807727</td>\n",
       "      <td>0.812202</td>\n",
       "      <td>0.812571</td>\n",
       "      <td>0.817392</td>\n",
       "      <td>0.811536</td>\n",
       "      <td>0.003588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.459391</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>250</td>\n",
       "      <td>{'min_samples_leaf': 250}</td>\n",
       "      <td>0.802190</td>\n",
       "      <td>0.813140</td>\n",
       "      <td>0.809048</td>\n",
       "      <td>0.817099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810381</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>5</td>\n",
       "      <td>0.803084</td>\n",
       "      <td>0.810346</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.811975</td>\n",
       "      <td>0.812035</td>\n",
       "      <td>0.809571</td>\n",
       "      <td>0.003324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.418751</td>\n",
       "      <td>0.018226</td>\n",
       "      <td>0.015632</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>300</td>\n",
       "      <td>{'min_samples_leaf': 300}</td>\n",
       "      <td>0.806951</td>\n",
       "      <td>0.808855</td>\n",
       "      <td>0.812857</td>\n",
       "      <td>0.815432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811333</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>3</td>\n",
       "      <td>0.811953</td>\n",
       "      <td>0.808322</td>\n",
       "      <td>0.813810</td>\n",
       "      <td>0.810547</td>\n",
       "      <td>0.813642</td>\n",
       "      <td>0.811655</td>\n",
       "      <td>0.002050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.600036      0.045294         0.015707        0.000147   \n",
       "1       0.513414      0.026510         0.012501        0.006250   \n",
       "2       0.474990      0.030583         0.012497        0.006248   \n",
       "3       0.459391      0.021189         0.012492        0.006246   \n",
       "4       0.418751      0.018226         0.015632        0.000006   \n",
       "\n",
       "  param_min_samples_leaf                     params  split0_test_score  \\\n",
       "0                    100  {'min_samples_leaf': 100}           0.811950   \n",
       "1                    150  {'min_samples_leaf': 150}           0.819091   \n",
       "2                    200  {'min_samples_leaf': 200}           0.806713   \n",
       "3                    250  {'min_samples_leaf': 250}           0.802190   \n",
       "4                    300  {'min_samples_leaf': 300}           0.806951   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0           0.819805           0.811905           0.815909       ...          \n",
       "1           0.818615           0.808571           0.822339       ...          \n",
       "2           0.806237           0.810238           0.815432       ...          \n",
       "3           0.813140           0.809048           0.817099       ...          \n",
       "4           0.808855           0.812857           0.815432       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.815143        0.002967                2            0.819454   \n",
       "1         0.816381        0.004866                1            0.819454   \n",
       "2         0.810810        0.004019                4            0.807786   \n",
       "3         0.810381        0.004932                5            0.803084   \n",
       "4         0.811333        0.003034                3            0.811953   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.822847            0.815179            0.820130   \n",
       "1            0.818858            0.811548            0.816380   \n",
       "2            0.807727            0.812202            0.812571   \n",
       "3            0.810346            0.810417            0.811975   \n",
       "4            0.808322            0.813810            0.810547   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.822272          0.819976         0.002714  \n",
       "1            0.815368          0.816322         0.002827  \n",
       "2            0.817392          0.811536         0.003588  \n",
       "3            0.812035          0.809571         0.003324  \n",
       "4            0.813642          0.811655         0.002050  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracies with min_samples_leaf\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_leaf\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " the model starts of overfit as you decrease the value of min_samples_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning min_samples_split\n",
    "\n",
    "Let's now look at the performance of the ensemble as we vary min_samples_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomForestClassifier in module sklearn.ensemble.forest:\n",
      "\n",
      "class RandomForestClassifier(ForestClassifier)\n",
      " |  A random forest classifier.\n",
      " |  \n",
      " |  A random forest is a meta estimator that fits a number of decision tree\n",
      " |  classifiers on various sub-samples of the dataset and use averaging to\n",
      " |  improve the predictive accuracy and control over-fitting.\n",
      " |  The sub-sample size is always the same as the original\n",
      " |  input sample size but the samples are drawn with replacement if\n",
      " |  `bootstrap=True` (default).\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <forest>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : integer, optional (default=10)\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |  criterion : string, optional (default=\"gini\")\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      " |      Note: this parameter is tree-specific.\n",
      " |  \n",
      " |  max_features : int, float, string or None, optional (default=\"auto\")\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a percentage and\n",
      " |        `int(max_features * n_features)` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)` (same as \"auto\").\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_depth : integer or None, optional (default=None)\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int, float, optional (default=2)\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a percentage and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for percentages.\n",
      " |  \n",
      " |  min_samples_leaf : int, float, optional (default=1)\n",
      " |      The minimum number of samples required to be at a leaf node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a percentage and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for percentages.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, optional (default=0.)\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_leaf_nodes : int or None, optional (default=None)\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_split : float,\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``min_impurity_split`` has been deprecated in favor of\n",
      " |         ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.\n",
      " |         Use ``min_impurity_decrease`` instead.\n",
      " |  \n",
      " |  min_impurity_decrease : float, optional (default=0.)\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  bootstrap : boolean, optional (default=True)\n",
      " |      Whether bootstrap samples are used when building trees.\n",
      " |  \n",
      " |  oob_score : bool (default=False)\n",
      " |      Whether to use out-of-bag samples to estimate\n",
      " |      the generalization accuracy.\n",
      " |  \n",
      " |  n_jobs : integer, optional (default=1)\n",
      " |      The number of jobs to run in parallel for both `fit` and `predict`.\n",
      " |      If -1, then the number of jobs is set to the number of cores.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  verbose : int, optional (default=0)\n",
      " |      Controls the verbosity of the tree building process.\n",
      " |  \n",
      " |  warm_start : bool, optional (default=False)\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest.\n",
      " |  \n",
      " |  class_weight : dict, list of dicts, \"balanced\",\n",
      " |      \"balanced_subsample\" or None, optional (default=None)\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one. For\n",
      " |      multi-output problems, a list of dicts can be provided in the same\n",
      " |      order as the columns of y.\n",
      " |  \n",
      " |      Note that for multioutput (including multilabel) weights should be\n",
      " |      defined for each class of every column in its own dict. For example,\n",
      " |      for four-class multilabel classification weights should be\n",
      " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |      The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
      " |      weights are computed based on the bootstrap sample for every tree\n",
      " |      grown.\n",
      " |  \n",
      " |      For multi-output, the weights of each column of y will be multiplied.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  estimators_ : list of DecisionTreeClassifier\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  classes_ : array of shape = [n_classes] or a list of such arrays\n",
      " |      The classes labels (single output problem), or a list of arrays of\n",
      " |      class labels (multi-output problem).\n",
      " |  \n",
      " |  n_classes_ : int or list\n",
      " |      The number of classes (single output problem), or a list containing the\n",
      " |      number of classes for each output (multi-output problem).\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  feature_importances_ : array of shape = [n_features]\n",
      " |      The feature importances (the higher, the more important the feature).\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |  \n",
      " |  oob_decision_function_ : array of shape = [n_samples, n_classes]\n",
      " |      Decision function computed with out-of-bag estimate on the training\n",
      " |      set. If n_estimators is small it might be possible that a data point\n",
      " |      was never left out during the bootstrap. In this case,\n",
      " |      `oob_decision_function_` might contain NaN.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import RandomForestClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>>\n",
      " |  >>> X, y = make_classification(n_samples=1000, n_features=4,\n",
      " |  ...                            n_informative=2, n_redundant=0,\n",
      " |  ...                            random_state=0, shuffle=False)\n",
      " |  >>> clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
      " |  >>> clf.fit(X, y)\n",
      " |  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      " |              max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      " |              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      " |              min_samples_leaf=1, min_samples_split=2,\n",
      " |              min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      " |              oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      " |  >>> print(clf.feature_importances_)\n",
      " |  [ 0.17287856  0.80608704  0.01884792  0.00218648]\n",
      " |  >>> print(clf.predict([[0, 0, 0, 0]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data,\n",
      " |  ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      " |  of the criterion is identical for several splits enumerated during the\n",
      " |  search of the best split. To obtain a deterministic behaviour during\n",
      " |  fitting, ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  DecisionTreeClassifier, ExtraTreesClassifier\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomForestClassifier\n",
      " |      ForestClassifier\n",
      " |      abc.NewBase\n",
      " |      BaseForest\n",
      " |      abc.NewBase\n",
      " |      sklearn.ensemble.base.BaseEnsemble\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False, class_weight=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestClassifier:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class for X.\n",
      " |      \n",
      " |      The predicted class of an input sample is a vote by the trees in\n",
      " |      the forest, weighted by their probability estimates. That is,\n",
      " |      the predicted class is the one with highest mean probability\n",
      " |      estimate across the trees.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array of shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      The predicted class log-probabilities of an input sample is computed as\n",
      " |      the log of the mean predicted class probabilities of the trees in the\n",
      " |      forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      The predicted class probabilities of an input sample are computed as\n",
      " |      the mean predicted class probabilities of the trees in the forest. The\n",
      " |      class probability of a single tree is the fraction of samples of the same\n",
      " |      class in a leaf.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape = [n_samples, n_estimators]\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  decision_path(self, X)\n",
      " |      Return the decision path in the forest\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse csr array, shape = [n_samples, n_nodes]\n",
      " |          Return a node indicator matrix where non zero elements\n",
      " |          indicates that the samples goes through the nodes.\n",
      " |      \n",
      " |      n_nodes_ptr : array of size (n_estimators + 1, )\n",
      " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
      " |          gives the indicator value for the i-th estimator.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The training input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples] or None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Return the feature importances (the higher, the more important the\n",
      " |         feature).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array, shape = [n_features]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble.base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Returns the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Returns iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_split': range(200, 500, 50)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV to find optimal min_samples_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_split': range(200, 500, 50)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.168989</td>\n",
       "      <td>0.342932</td>\n",
       "      <td>0.028650</td>\n",
       "      <td>0.016589</td>\n",
       "      <td>200</td>\n",
       "      <td>{'min_samples_split': 200}</td>\n",
       "      <td>0.819567</td>\n",
       "      <td>0.817900</td>\n",
       "      <td>0.821905</td>\n",
       "      <td>0.822101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819857</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>1</td>\n",
       "      <td>0.825347</td>\n",
       "      <td>0.824573</td>\n",
       "      <td>0.827143</td>\n",
       "      <td>0.825665</td>\n",
       "      <td>0.827272</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.001049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.937543</td>\n",
       "      <td>0.151496</td>\n",
       "      <td>0.017576</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>250</td>\n",
       "      <td>{'min_samples_split': 250}</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.820757</td>\n",
       "      <td>0.817381</td>\n",
       "      <td>0.822101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819286</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>3</td>\n",
       "      <td>0.824751</td>\n",
       "      <td>0.823740</td>\n",
       "      <td>0.822798</td>\n",
       "      <td>0.822927</td>\n",
       "      <td>0.826558</td>\n",
       "      <td>0.824155</td>\n",
       "      <td>0.001389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.829088</td>\n",
       "      <td>0.103162</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>0.007261</td>\n",
       "      <td>300</td>\n",
       "      <td>{'min_samples_split': 300}</td>\n",
       "      <td>0.821471</td>\n",
       "      <td>0.818139</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.822577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818905</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>4</td>\n",
       "      <td>0.824097</td>\n",
       "      <td>0.824097</td>\n",
       "      <td>0.822798</td>\n",
       "      <td>0.821320</td>\n",
       "      <td>0.823106</td>\n",
       "      <td>0.823083</td>\n",
       "      <td>0.001024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.762859</td>\n",
       "      <td>0.060262</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>350</td>\n",
       "      <td>{'min_samples_split': 350}</td>\n",
       "      <td>0.814092</td>\n",
       "      <td>0.824804</td>\n",
       "      <td>0.819524</td>\n",
       "      <td>0.822101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819571</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>2</td>\n",
       "      <td>0.819334</td>\n",
       "      <td>0.822251</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.822927</td>\n",
       "      <td>0.823225</td>\n",
       "      <td>0.822131</td>\n",
       "      <td>0.001434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.742247</td>\n",
       "      <td>0.054637</td>\n",
       "      <td>0.018755</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>400</td>\n",
       "      <td>{'min_samples_split': 400}</td>\n",
       "      <td>0.819329</td>\n",
       "      <td>0.818139</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.818290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818286</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>5</td>\n",
       "      <td>0.820823</td>\n",
       "      <td>0.819751</td>\n",
       "      <td>0.819702</td>\n",
       "      <td>0.817749</td>\n",
       "      <td>0.824594</td>\n",
       "      <td>0.820524</td>\n",
       "      <td>0.002264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.168989      0.342932         0.028650        0.016589   \n",
       "1       0.937543      0.151496         0.017576        0.002243   \n",
       "2       0.829088      0.103162         0.008734        0.007261   \n",
       "3       0.762859      0.060262         0.014286        0.003100   \n",
       "4       0.742247      0.054637         0.018755        0.006249   \n",
       "\n",
       "  param_min_samples_split                      params  split0_test_score  \\\n",
       "0                     200  {'min_samples_split': 200}           0.819567   \n",
       "1                     250  {'min_samples_split': 250}           0.817662   \n",
       "2                     300  {'min_samples_split': 300}           0.821471   \n",
       "3                     350  {'min_samples_split': 350}           0.814092   \n",
       "4                     400  {'min_samples_split': 400}           0.819329   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0           0.817900           0.821905           0.822101       ...          \n",
       "1           0.820757           0.817381           0.822101       ...          \n",
       "2           0.818139           0.819048           0.822577       ...          \n",
       "3           0.824804           0.819524           0.822101       ...          \n",
       "4           0.818139           0.817857           0.818290       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.819857        0.001861                1            0.825347   \n",
       "1         0.819286        0.001840                3            0.824751   \n",
       "2         0.818905        0.003231                4            0.824097   \n",
       "3         0.819571        0.003709                2            0.819334   \n",
       "4         0.818286        0.000551                5            0.820823   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.824573            0.827143            0.825665   \n",
       "1            0.823740            0.822798            0.822927   \n",
       "2            0.824097            0.822798            0.821320   \n",
       "3            0.822251            0.822917            0.822927   \n",
       "4            0.819751            0.819702            0.817749   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.827272          0.826000         0.001049  \n",
       "1            0.826558          0.824155         0.001389  \n",
       "2            0.823106          0.823083         0.001024  \n",
       "3            0.823225          0.822131         0.001434  \n",
       "4            0.824594          0.820524         0.002264  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracies with min_samples_split\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search to Find Optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [4,8,10],\n",
    "    'min_samples_leaf': range(100, 400, 200),\n",
    "    'min_samples_split': range(200, 500, 200),\n",
    "    'n_estimators': [100,200, 300], \n",
    "    'max_features': [5, 10]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed: 16.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_depth': [4, 8, 10], 'min_samples_leaf': range(100, 400, 200), 'min_samples_split': range(200, 500, 200), 'n_estimators': [100, 200, 300], 'max_features': [5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get accuracy of 0.8209047619047619 using {'max_depth': 10, 'max_features': 5, 'min_samples_leaf': 100, 'min_samples_split': 400, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting the final model with the best parameters obtained from grid search.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(bootstrap=True,\n",
    "                             max_depth=10,\n",
    "                             min_samples_leaf=100, \n",
    "                             min_samples_split=200,\n",
    "                             max_features=10,\n",
    "                             n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features=10, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=100, min_samples_split=200,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.89      6982\n",
      "          1       0.70      0.36      0.48      2018\n",
      "\n",
      "avg / total       0.81      0.82      0.80      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6665  317]\n",
      " [1289  729]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8215555555555556\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
